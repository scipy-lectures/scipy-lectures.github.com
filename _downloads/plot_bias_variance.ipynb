{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Bias and variance of polynomial fit\n\n\nDemo overfitting, underfitting, and validation and learning curves with\npolynomial regression.\n\nFit polynomes of different degrees to a dataset: for too small a degree,\nthe model *underfits*, while for too large a degree, it overfits.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport matplotlib.pyplot as plt\n\n\ndef generating_func(x, err=0.5):\n    return np.random.normal(10 - 1. / (x + 0.1), err)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A polynomial regression\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import make_pipeline\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A simple figure to illustrate the problem\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_samples = 8\n\nnp.random.seed(0)\nx = 10 ** np.linspace(-2, 0, n_samples)\ny = generating_func(x)\n\nx_test = np.linspace(-0.2, 1.2, 1000)\n\ntitles = ['d = 1 (under-fit; high bias)',\n          'd = 2',\n          'd = 6 (over-fit; high variance)']\ndegrees = [1, 2, 6]\n\nfig = plt.figure(figsize=(9, 3.5))\nfig.subplots_adjust(left=0.06, right=0.98, bottom=0.15, top=0.85, wspace=0.05)\n\nfor i, d in enumerate(degrees):\n    ax = fig.add_subplot(131 + i, xticks=[], yticks=[])\n    ax.scatter(x, y, marker='x', c='k', s=50)\n\n    model = make_pipeline(PolynomialFeatures(d), LinearRegression())\n    model.fit(x[:, np.newaxis], y)\n    ax.plot(x_test, model.predict(x_test[:, np.newaxis]), '-b')\n\n    ax.set_xlim(-0.2, 1.2)\n    ax.set_ylim(0, 12)\n    ax.set_xlabel('house size')\n    if i == 0:\n        ax.set_ylabel('price')\n\n    ax.set_title(titles[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate a larger dataset\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n\nn_samples = 200\ntest_size = 0.4\nerror = 1.0\n\n# randomly sample the data\nnp.random.seed(1)\nx = np.random.random(n_samples)\ny = generating_func(x, error)\n\n# split into training, validation, and testing sets.\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size)\n\n# show the training and validation sets\nplt.figure(figsize=(6, 4))\nplt.scatter(x_train, y_train, color='red', label='Training set')\nplt.scatter(x_test, y_test, color='blue', label='Test set')\nplt.title('The data')\nplt.legend(loc='best')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot a validation curve\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import validation_curve\n\ndegrees = np.arange(1, 21)\n\nmodel = make_pipeline(PolynomialFeatures(), LinearRegression())\n\n# The parameter to vary is the \"degrees\" on the pipeline step\n# \"polynomialfeatures\"\ntrain_scores, validation_scores = validation_curve(\n                 model, x[:, np.newaxis], y,\n                 param_name='polynomialfeatures__degree',\n                 param_range=degrees)\n\n# Plot the mean train error and validation error across folds\nplt.figure(figsize=(6, 4))\nplt.plot(degrees, validation_scores.mean(axis=1), lw=2,\n         label='cross-validation')\nplt.plot(degrees, train_scores.mean(axis=1), lw=2, label='training')\n\nplt.legend(loc='best')\nplt.xlabel('degree of fit')\nplt.ylabel('explained variance')\nplt.title('Validation curve')\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Learning curves\n###########################################################\n\n Plot train and test error with an increasing number of samples\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# A learning curve for d=1, 5, 15\nfor d in [1, 5, 15]:\n    model = make_pipeline(PolynomialFeatures(degree=d), LinearRegression())\n\n    from sklearn.model_selection import learning_curve\n    train_sizes, train_scores, validation_scores = learning_curve(\n        model, x[:, np.newaxis], y,\n        train_sizes=np.logspace(-1, 0, 20))\n\n    # Plot the mean train error and validation error across folds\n    plt.figure(figsize=(6, 4))\n    plt.plot(train_sizes, validation_scores.mean(axis=1),\n            lw=2, label='cross-validation')\n    plt.plot(train_sizes, train_scores.mean(axis=1),\n                lw=2, label='training')\n    plt.ylim(ymin=-.1, ymax=1)\n\n    plt.legend(loc='best')\n    plt.xlabel('number of train samples')\n    plt.ylabel('explained variance')\n    plt.title('Learning curve (degree=%i)' % d)\n    plt.tight_layout()\n\n\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}