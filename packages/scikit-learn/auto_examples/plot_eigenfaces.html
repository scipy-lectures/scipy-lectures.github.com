
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>3.6.9.14. The eigenfaces example: chaining PCA and SVMs &#8212; Scipy lecture notes</title>
    <link rel="stylesheet" href="../../../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/gallery.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../../',
        VERSION:     '2017.1.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../../_static/copybutton.js"></script>
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="3.6.9.15. Example of linear and non-linear models" href="plot_svm_non_linear.html" />
    <link rel="prev" title="3.6.9.13. Simple visualization and classification of the digits dataset" href="plot_digits_simple_classif.html" />
   
    <link rel="stylesheet"
	  href="https://unpkg.com/purecss@1.0.0/build/base-min.css">

<script type="text/javascript">
$(function () {
    // Highlight the table of content as we scroll
    sections = {},
    i        = 0,
    url	 = document.URL.replace(/#.*$/, ""),
    current_section = 0;

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50;
    });

    $(window).scroll(function(event) {
	var pos   = $(window).scrollTop();

	// Highlight the current section
	$('a.internal').parent().removeClass('active');
        for(i in sections){
            if(sections[i] > pos){
		break;
            };
	    if($('a.internal[href$="' + i + '"]').is(':visible')){
		current_section = i;
	    };
        }
	$('a.internal[href$="' + current_section + '"]').parent().addClass('active');
	$('a.internal[href$="' + current_section + '"]').parent().parent().parent().addClass('active');
	$('a.internal[href$="' + current_section + '"]').parent().parent().parent().parent().parent().addClass('active');
    });

});
</script>


  </head>
  <body>
   <!-- Use the header to add javascript -->
    

    <script type="text/javascript">
    // Function to collapse the tip divs
    function collapse_tip_div(obj){
	// Update the representation on the tip div based on whether it
	// has the 'collapsed' css class or not: we only want to
	// collapse divs that are not already collapsed
	if($(obj).hasClass("collapsed")) {
	} else {
	    $(obj).find("p.summary").remove();
	    var content = $(obj).text();
	    var html = $(obj).html();

	    if(content.length > 40) {
		if ($.browser.msie) {
		    // We start at '3' to avoid 'tip', as IE
		    // does not count whitespace
		    var content = content.substr(3, 50);
		} else {
		    // We start at '5' to avoid 'tip '
		    var content = content.substr(5, 50);
		}
	    }
	    $(obj).html('<p class="summary"><img src="../../../_static/plus.png">' + content + '...</p>' + html);
	}
    }
    </script>

    <script type="text/javascript">
    $(function () {
	$(".tip")
	    .click(function(event){
		$(this).toggleClass("collapsed");
		// Change state of the global button
		$('div.related li.transparent').removeClass('transparent')
		$(this).find("p.summary").remove();
		if($(this).hasClass("collapsed")) {
		    var content = $(this).text();
		    var html = $(this).html();

		    if(content.length > 40) {
			if ($.browser.msie) {
			    // We start at '3' to avoid 'tip', as IE
			    // does not count whitespace
			    var content = content.substr(3, 50);
			} else {
			    // We start at '5' to avoid 'tip '
			    var content = content.substr(5, 50);
			}
		    }
		    $(this).html('<p class="summary"><img src="../../../_static/plus.png">' + content + '...</p>' + html);
		}
		if (event.target.tagName.toLowerCase() != "a") {
                   return true; //Makes links clickable
		}
	});
    });
    </script>


    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="plot_svm_non_linear.html" title="3.6.9.15. Example of linear and non-linear models"
             accesskey="N">next</a></li>
        <li class="right" >
          <a href="plot_digits_simple_classif.html" title="3.6.9.13. Simple visualization and classification of the digits dataset"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../../index.html">Scipy lecture notes</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../index.html" >3. Packages and applications</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../index.html" accesskey="U">3.6. scikit-learn: machine learning in Python</a> &#187;</li>
     
    <!-- Insert a menu in the navigation bar -->
    <li class="left">
	<!-- On click toggle the 'tip' on or off-->
	<a onclick="$('.tip').each(function (index, obj) {
			    collapse_tip_div(obj);
		    });
		    $('.tip').addClass('collapsed');
		    $('.left').addClass('transparent');">
	<img src="../../../_static/minus.png"
         alt="Collapse to compact view" style="padding: 1ex;"/>
	<span class="hiddenlink">Collapse document to compact view</span>
    </a></li>
    <li class="right edit_on_github"><a href="https://github.com/scipy-lectures/scipy-lecture-notes/edit/master/packages/scikit-learn/auto_examples/plot_eigenfaces.rst">Edit
    <span class="tooltip">
	Improve this page:<br/>Edit it on Github.
    </span>
    </a>
    </li>

      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="the-eigenfaces-example-chaining-pca-and-svms">
<span id="sphx-glr-packages-scikit-learn-auto-examples-plot-eigenfaces-py"></span><h1>3.6.9.14. The eigenfaces example: chaining PCA and SVMs<a class="headerlink" href="#the-eigenfaces-example-chaining-pca-and-svms" title="Permalink to this headline">¶</a></h1>
<p>The goal of this example is to show how an unsupervised method and a
supervised one can be chained for better prediction. It starts with a
didactic but lengthy way of doing things, and finishes with the
idiomatic approach to pipelining in scikit-learn.</p>
<p>Here we’ll take a look at a simple facial recognition example. Ideally,
we would use a dataset consisting of a subset of the <a class="reference external" href="http://vis-www.cs.umass.edu/lfw/">Labeled Faces in
the Wild</a> data that is available
with <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_lfw_people.html#sklearn.datasets.fetch_lfw_people" title="(in scikit-learn v0.19.1)"><code class="xref py py-func docutils literal"><span class="pre">sklearn.datasets.fetch_lfw_people()</span></code></a>. However, this is a
relatively large download (~200MB) so we will do the tutorial on a
simpler, less rich dataset. Feel free to explore the LFW dataset.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<div class="newline"></div><span class="n">faces</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">fetch_olivetti_faces</span><span class="p">()</span>
<div class="newline"></div><span class="n">faces</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span>
<div class="newline"></div></pre></div>
</div>
<p>Let’s visualize these faces to see what we’re working with</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<div class="newline"></div><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<div class="newline"></div><span class="c1"># plot several images</span>
<div class="newline"></div><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">15</span><span class="p">):</span>
<div class="newline"></div>    <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">xticks</span><span class="o">=</span><span class="p">[],</span> <span class="n">yticks</span><span class="o">=</span><span class="p">[])</span>
<div class="newline"></div>    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">faces</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">bone</span><span class="p">)</span>
<div class="newline"></div></pre></div>
</div>
<img alt="../../../_images/sphx_glr_plot_eigenfaces_001.png" class="align-center" src="../../../_images/sphx_glr_plot_eigenfaces_001.png" />
<div class="admonition tip">
<p class="first admonition-title">Tip</p>
<p class="last">Note is that these faces have already been localized and scaled to a
common size. This is an important preprocessing piece for facial
recognition, and is a process that can require a large collection of
training data. This can be done in scikit-learn, but the challenge is
gathering a sufficient amount of training data for the algorithm to work.
Fortunately, this piece is common enough that it has been done. One good
resource is
<a class="reference external" href="http://opencv.willowgarage.com/wiki/FaceRecognition">OpenCV</a>, the
<em>Open Computer Vision Library</em>.</p>
</div>
<p>We’ll perform a Support Vector classification of the images. We’ll do a
typical train-test split on the images:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<div class="newline"></div><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">faces</span><span class="o">.</span><span class="n">data</span><span class="p">,</span>
<div class="newline"></div>        <span class="n">faces</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<div class="newline"></div>
<div class="newline"></div><span class="k">print</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<div class="newline"></div></pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default"><div class="highlight"><pre><span></span><span class="p">(</span><span class="mi">300</span><span class="p">,</span> <span class="mi">4096</span><span class="p">)</span> <span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">4096</span><span class="p">)</span>
<div class="newline"></div></pre></div>
</div>
<div class="section" id="preprocessing-principal-component-analysis">
<h2>Preprocessing: Principal Component Analysis<a class="headerlink" href="#preprocessing-principal-component-analysis" title="Permalink to this headline">¶</a></h2>
<p>1850 dimensions is a lot for SVM. We can use PCA to reduce these 1850
features to a manageable size, while maintaining most of the information
in the dataset.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">decomposition</span>
<div class="newline"></div><span class="n">pca</span> <span class="o">=</span> <span class="n">decomposition</span><span class="o">.</span><span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span> <span class="n">whiten</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<div class="newline"></div><span class="n">pca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<div class="newline"></div></pre></div>
</div>
<p>One interesting part of PCA is that it computes the “mean” face, which
can be interesting to examine:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">mean_</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">faces</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span>
<div class="newline"></div>           <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">bone</span><span class="p">)</span>
<div class="newline"></div></pre></div>
</div>
<img alt="../../../_images/sphx_glr_plot_eigenfaces_002.png" class="align-center" src="../../../_images/sphx_glr_plot_eigenfaces_002.png" />
<p>The principal components measure deviations about this mean along
orthogonal axes.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">components_</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<div class="newline"></div></pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default"><div class="highlight"><pre><span></span><span class="p">(</span><span class="mi">150</span><span class="p">,</span> <span class="mi">4096</span><span class="p">)</span>
<div class="newline"></div></pre></div>
</div>
<p>It is also interesting to visualize these principal components:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<div class="newline"></div><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">30</span><span class="p">):</span>
<div class="newline"></div>    <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">xticks</span><span class="o">=</span><span class="p">[],</span> <span class="n">yticks</span><span class="o">=</span><span class="p">[])</span>
<div class="newline"></div>    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">components_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">faces</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span>
<div class="newline"></div>              <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">bone</span><span class="p">)</span>
<div class="newline"></div></pre></div>
</div>
<img alt="../../../_images/sphx_glr_plot_eigenfaces_003.png" class="align-center" src="../../../_images/sphx_glr_plot_eigenfaces_003.png" />
<p>The components (“eigenfaces”) are ordered by their importance from
top-left to bottom-right. We see that the first few components seem to
primarily take care of lighting conditions; the remaining components
pull out certain identifying features: the nose, eyes, eyebrows, etc.</p>
<p>With this projection computed, we can now project our original training
and test data onto the PCA basis:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">X_train_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<div class="newline"></div><span class="n">X_test_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<div class="newline"></div><span class="k">print</span><span class="p">(</span><span class="n">X_train_pca</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<div class="newline"></div></pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default"><div class="highlight"><pre><span></span><span class="p">(</span><span class="mi">300</span><span class="p">,</span> <span class="mi">150</span><span class="p">)</span>
<div class="newline"></div></pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">X_test_pca</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<div class="newline"></div></pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default"><div class="highlight"><pre><span></span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">150</span><span class="p">)</span>
<div class="newline"></div></pre></div>
</div>
<p>These projected components correspond to factors in a linear combination
of component images such that the combination approaches the original
face.</p>
</div>
<div class="section" id="doing-the-learning-support-vector-machines">
<h2>Doing the Learning: Support Vector Machines<a class="headerlink" href="#doing-the-learning-support-vector-machines" title="Permalink to this headline">¶</a></h2>
<p>Now we’ll perform support-vector-machine classification on this reduced
dataset:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">svm</span>
<div class="newline"></div><span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mf">5.</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
<div class="newline"></div><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_pca</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<div class="newline"></div></pre></div>
</div>
<p>Finally, we can evaluate how well this classification did. First, we
might plot a few of the test-cases with the labels learned from the
training set:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<div class="newline"></div><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<div class="newline"></div><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">15</span><span class="p">):</span>
<div class="newline"></div>    <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">xticks</span><span class="o">=</span><span class="p">[],</span> <span class="n">yticks</span><span class="o">=</span><span class="p">[])</span>
<div class="newline"></div>    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">faces</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span>
<div class="newline"></div>              <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">bone</span><span class="p">)</span>
<div class="newline"></div>    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_pca</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
<div class="newline"></div>    <span class="n">color</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;black&#39;</span> <span class="k">if</span> <span class="n">y_pred</span> <span class="o">==</span> <span class="n">y_test</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">else</span> <span class="s1">&#39;red&#39;</span><span class="p">)</span>
<div class="newline"></div>    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">faces</span><span class="o">.</span><span class="n">target</span><span class="p">[</span><span class="n">y_pred</span><span class="p">],</span>
<div class="newline"></div>                 <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;small&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>
<div class="newline"></div></pre></div>
</div>
<img alt="../../../_images/sphx_glr_plot_eigenfaces_004.png" class="align-center" src="../../../_images/sphx_glr_plot_eigenfaces_004.png" />
<p>The classifier is correct on an impressive number of images given the
simplicity of its learning model! Using a linear classifier on 150
features derived from the pixel-level data, the algorithm correctly
identifies a large number of the people in the images.</p>
<p>Again, we can quantify this effectiveness using one of several measures
from <a class="reference external" href="http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics" title="(in scikit-learn v0.19.1)"><code class="xref py py-mod docutils literal"><span class="pre">sklearn.metrics</span></code></a>. First we can do the classification
report, which shows the precision, recall and other measures of the
“goodness” of the classification:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<div class="newline"></div><span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_pca</span><span class="p">)</span>
<div class="newline"></div><span class="k">print</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<div class="newline"></div></pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default"><div class="highlight"><pre><span></span><span class="n">precision</span>    <span class="n">recall</span>  <span class="n">f1</span><span class="o">-</span><span class="n">score</span>   <span class="n">support</span>
<div class="newline"></div>
<div class="newline"></div>          <span class="mi">0</span>       <span class="mf">1.00</span>      <span class="mf">0.67</span>      <span class="mf">0.80</span>         <span class="mi">6</span>
<div class="newline"></div>          <span class="mi">1</span>       <span class="mf">1.00</span>      <span class="mf">1.00</span>      <span class="mf">1.00</span>         <span class="mi">4</span>
<div class="newline"></div>          <span class="mi">2</span>       <span class="mf">0.50</span>      <span class="mf">1.00</span>      <span class="mf">0.67</span>         <span class="mi">2</span>
<div class="newline"></div>          <span class="mi">3</span>       <span class="mf">1.00</span>      <span class="mf">1.00</span>      <span class="mf">1.00</span>         <span class="mi">1</span>
<div class="newline"></div>          <span class="mi">4</span>       <span class="mf">1.00</span>      <span class="mf">1.00</span>      <span class="mf">1.00</span>         <span class="mi">1</span>
<div class="newline"></div>          <span class="mi">5</span>       <span class="mf">1.00</span>      <span class="mf">1.00</span>      <span class="mf">1.00</span>         <span class="mi">5</span>
<div class="newline"></div>          <span class="mi">6</span>       <span class="mf">1.00</span>      <span class="mf">1.00</span>      <span class="mf">1.00</span>         <span class="mi">4</span>
<div class="newline"></div>          <span class="mi">7</span>       <span class="mf">1.00</span>      <span class="mf">0.67</span>      <span class="mf">0.80</span>         <span class="mi">3</span>
<div class="newline"></div>          <span class="mi">9</span>       <span class="mf">1.00</span>      <span class="mf">1.00</span>      <span class="mf">1.00</span>         <span class="mi">1</span>
<div class="newline"></div>         <span class="mi">10</span>       <span class="mf">1.00</span>      <span class="mf">1.00</span>      <span class="mf">1.00</span>         <span class="mi">4</span>
<div class="newline"></div>         <span class="mi">11</span>       <span class="mf">1.00</span>      <span class="mf">1.00</span>      <span class="mf">1.00</span>         <span class="mi">1</span>
<div class="newline"></div>         <span class="mi">12</span>       <span class="mf">0.67</span>      <span class="mf">1.00</span>      <span class="mf">0.80</span>         <span class="mi">2</span>
<div class="newline"></div>         <span class="mi">13</span>       <span class="mf">1.00</span>      <span class="mf">1.00</span>      <span class="mf">1.00</span>         <span class="mi">3</span>
<div class="newline"></div>         <span class="mi">14</span>       <span class="mf">1.00</span>      <span class="mf">1.00</span>      <span class="mf">1.00</span>         <span class="mi">5</span>
<div class="newline"></div>         <span class="mi">15</span>       <span class="mf">1.00</span>      <span class="mf">1.00</span>      <span class="mf">1.00</span>         <span class="mi">3</span>
<div class="newline"></div>         <span class="mi">17</span>       <span class="mf">1.00</span>      <span class="mf">1.00</span>      <span class="mf">1.00</span>         <span class="mi">6</span>
<div class="newline"></div>         <span class="mi">19</span>       <span class="mf">1.00</span>      <span class="mf">1.00</span>      <span class="mf">1.00</span>         <span class="mi">4</span>
<div class="newline"></div>         <span class="mi">20</span>       <span class="mf">1.00</span>      <span class="mf">1.00</span>      <span class="mf">1.00</span>         <span class="mi">1</span>
<div class="newline"></div>         <span class="mi">21</span>       <span class="mf">1.00</span>      <span class="mf">1.00</span>      <span class="mf">1.00</span>         <span class="mi">1</span>
<div class="newline"></div>         <span class="mi">22</span>       <span class="mf">1.00</span>      <span class="mf">1.00</span>      <span class="mf">1.00</span>         <span class="mi">2</span>
<div class="newline"></div>         <span class="mi">23</span>       <span class="mf">0.50</span>      <span class="mf">1.00</span>      <span class="mf">0.67</span>         <span class="mi">1</span>
<div class="newline"></div>         <span class="mi">24</span>       <span class="mf">1.00</span>      <span class="mf">1.00</span>      <span class="mf">1.00</span>         <span class="mi">2</span>
<div class="newline"></div>         <span class="mi">25</span>       <span class="mf">1.00</span>      <span class="mf">0.50</span>      <span class="mf">0.67</span>         <span class="mi">2</span>
<div class="newline"></div>         <span class="mi">26</span>       <span class="mf">1.00</span>      <span class="mf">0.75</span>      <span class="mf">0.86</span>         <span class="mi">4</span>
<div class="newline"></div>         <span class="mi">27</span>       <span class="mf">1.00</span>      <span class="mf">1.00</span>      <span class="mf">1.00</span>         <span class="mi">1</span>
<div class="newline"></div>         <span class="mi">28</span>       <span class="mf">0.67</span>      <span class="mf">1.00</span>      <span class="mf">0.80</span>         <span class="mi">2</span>
<div class="newline"></div>         <span class="mi">29</span>       <span class="mf">1.00</span>      <span class="mf">1.00</span>      <span class="mf">1.00</span>         <span class="mi">3</span>
<div class="newline"></div>         <span class="mi">30</span>       <span class="mf">1.00</span>      <span class="mf">1.00</span>      <span class="mf">1.00</span>         <span class="mi">4</span>
<div class="newline"></div>         <span class="mi">31</span>       <span class="mf">1.00</span>      <span class="mf">1.00</span>      <span class="mf">1.00</span>         <span class="mi">3</span>
<div class="newline"></div>         <span class="mi">32</span>       <span class="mf">1.00</span>      <span class="mf">1.00</span>      <span class="mf">1.00</span>         <span class="mi">3</span>
<div class="newline"></div>         <span class="mi">33</span>       <span class="mf">1.00</span>      <span class="mf">1.00</span>      <span class="mf">1.00</span>         <span class="mi">2</span>
<div class="newline"></div>         <span class="mi">34</span>       <span class="mf">1.00</span>      <span class="mf">1.00</span>      <span class="mf">1.00</span>         <span class="mi">3</span>
<div class="newline"></div>         <span class="mi">35</span>       <span class="mf">1.00</span>      <span class="mf">1.00</span>      <span class="mf">1.00</span>         <span class="mi">1</span>
<div class="newline"></div>         <span class="mi">36</span>       <span class="mf">1.00</span>      <span class="mf">1.00</span>      <span class="mf">1.00</span>         <span class="mi">3</span>
<div class="newline"></div>         <span class="mi">37</span>       <span class="mf">1.00</span>      <span class="mf">1.00</span>      <span class="mf">1.00</span>         <span class="mi">3</span>
<div class="newline"></div>         <span class="mi">38</span>       <span class="mf">1.00</span>      <span class="mf">1.00</span>      <span class="mf">1.00</span>         <span class="mi">1</span>
<div class="newline"></div>         <span class="mi">39</span>       <span class="mf">1.00</span>      <span class="mf">1.00</span>      <span class="mf">1.00</span>         <span class="mi">3</span>
<div class="newline"></div>
<div class="newline"></div><span class="n">avg</span> <span class="o">/</span> <span class="n">total</span>       <span class="mf">0.97</span>      <span class="mf">0.95</span>      <span class="mf">0.95</span>       <span class="mi">100</span>
<div class="newline"></div></pre></div>
</div>
<p>Another interesting metric is the <em>confusion matrix</em>, which indicates
how often any two items are mixed-up. The confusion matrix of a perfect
classifier would only have nonzero entries on the diagonal, with zeros
on the off-diagonal:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<div class="newline"></div></pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default"><div class="highlight"><pre><span></span><span class="p">[[</span><span class="mi">4</span> <span class="mi">0</span> <span class="mi">0</span> <span class="o">...</span><span class="p">,</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span><span class="p">]</span>
<div class="newline"></div> <span class="p">[</span><span class="mi">0</span> <span class="mi">4</span> <span class="mi">0</span> <span class="o">...</span><span class="p">,</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span><span class="p">]</span>
<div class="newline"></div> <span class="p">[</span><span class="mi">0</span> <span class="mi">0</span> <span class="mi">2</span> <span class="o">...</span><span class="p">,</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span><span class="p">]</span>
<div class="newline"></div> <span class="o">...</span><span class="p">,</span>
<div class="newline"></div> <span class="p">[</span><span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="o">...</span><span class="p">,</span> <span class="mi">3</span> <span class="mi">0</span> <span class="mi">0</span><span class="p">]</span>
<div class="newline"></div> <span class="p">[</span><span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="o">...</span><span class="p">,</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span><span class="p">]</span>
<div class="newline"></div> <span class="p">[</span><span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="o">...</span><span class="p">,</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">3</span><span class="p">]]</span>
<div class="newline"></div></pre></div>
</div>
</div>
<div class="section" id="pipelining">
<h2>Pipelining<a class="headerlink" href="#pipelining" title="Permalink to this headline">¶</a></h2>
<p>Above we used PCA as a pre-processing step before applying our support
vector machine classifier. Plugging the output of one estimator directly
into the input of a second estimator is a commonly used pattern; for
this reason scikit-learn provides a <code class="docutils literal"><span class="pre">Pipeline</span></code> object which automates
this process. The above problem can be re-expressed as a pipeline as
follows:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<div class="newline"></div><span class="n">clf</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s1">&#39;pca&#39;</span><span class="p">,</span> <span class="n">decomposition</span><span class="o">.</span><span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span> <span class="n">whiten</span><span class="o">=</span><span class="bp">True</span><span class="p">)),</span>
<div class="newline"></div>                <span class="p">(</span><span class="s1">&#39;svm&#39;</span><span class="p">,</span> <span class="n">svm</span><span class="o">.</span><span class="n">LinearSVC</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mf">1.0</span><span class="p">))])</span>
<div class="newline"></div>
<div class="newline"></div><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<div class="newline"></div>
<div class="newline"></div><span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<div class="newline"></div><span class="k">print</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
<div class="newline"></div><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<div class="newline"></div></pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default"><div class="highlight"><pre><span></span><span class="p">[[</span><span class="mi">5</span> <span class="mi">0</span> <span class="mi">0</span> <span class="o">...</span><span class="p">,</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span><span class="p">]</span>
<div class="newline"></div> <span class="p">[</span><span class="mi">0</span> <span class="mi">4</span> <span class="mi">0</span> <span class="o">...</span><span class="p">,</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span><span class="p">]</span>
<div class="newline"></div> <span class="p">[</span><span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="o">...</span><span class="p">,</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span><span class="p">]</span>
<div class="newline"></div> <span class="o">...</span><span class="p">,</span>
<div class="newline"></div> <span class="p">[</span><span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="o">...</span><span class="p">,</span> <span class="mi">3</span> <span class="mi">0</span> <span class="mi">0</span><span class="p">]</span>
<div class="newline"></div> <span class="p">[</span><span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="o">...</span><span class="p">,</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span><span class="p">]</span>
<div class="newline"></div> <span class="p">[</span><span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="o">...</span><span class="p">,</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">3</span><span class="p">]]</span>
<div class="newline"></div></pre></div>
</div>
</div>
<div class="section" id="a-note-on-facial-recognition">
<h2>A Note on Facial Recognition<a class="headerlink" href="#a-note-on-facial-recognition" title="Permalink to this headline">¶</a></h2>
<p>Here we have used PCA “eigenfaces” as a pre-processing step for facial
recognition. The reason we chose this is because PCA is a
broadly-applicable technique, which can be useful for a wide array of
data types. Research in the field of facial recognition in particular,
however, has shown that other more specific feature extraction methods
are can be much more effective.</p>
<p><strong>Total running time of the script:</strong> ( 0 minutes  8.566 seconds)</p>
<div class="sphx-glr-footer docutils container">
<div class="sphx-glr-download docutils container">
<a class="reference download internal" href="../../../_downloads/plot_eigenfaces.py" download=""><code class="xref download docutils literal"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_eigenfaces.py</span></code></a></div>
<div class="sphx-glr-download docutils container">
<a class="reference download internal" href="../../../_downloads/plot_eigenfaces.ipynb" download=""><code class="xref download docutils literal"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_eigenfaces.ipynb</span></code></a></div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.readthedocs.io">Generated by Sphinx-Gallery</a></p>
<p><div style="clear: both"></div></p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
	<div class="sidebartoc">
  <h3><a href="../../../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">3.6.9.14. The eigenfaces example: chaining PCA and SVMs</a><ul>
<li><a class="reference internal" href="#preprocessing-principal-component-analysis">Preprocessing: Principal Component Analysis</a></li>
<li><a class="reference internal" href="#doing-the-learning-support-vector-machines">Doing the Learning: Support Vector Machines</a></li>
<li><a class="reference internal" href="#pipelining">Pipelining</a></li>
<li><a class="reference internal" href="#a-note-on-facial-recognition">A Note on Facial Recognition</a></li>
</ul>
</li>
</ul>
</div>



    <div class="script_container">
    <script>
    (function() {
	var cx = '004523248466141510607:hgv2yimrahw';
	var gcse = document.createElement('script');
	gcse.type = 'text/javascript';
	gcse.async = true;
	gcse.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') +
	    '//cse.google.com/cse.js?cx=' + cx;
	var s = document.getElementsByTagName('script')[0];
	s.parentNode.insertBefore(gcse, s);
    })();
    </script>
    <gcse:search></gcse:search>
    </div>

        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="plot_svm_non_linear.html" title="3.6.9.15. Example of linear and non-linear models"
             >next</a></li>
        <li class="right" >
          <a href="plot_digits_simple_classif.html" title="3.6.9.13. Simple visualization and classification of the digits dataset"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../../index.html">Scipy lecture notes</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../index.html" >3. Packages and applications</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../index.html" >3.6. scikit-learn: machine learning in Python</a> &#187;</li>
     
    <!-- Insert a menu in the navigation bar -->
    <li class="left">
	<!-- On click toggle the 'tip' on or off-->
	<a onclick="$('.tip').each(function (index, obj) {
			    collapse_tip_div(obj);
		    });
		    $('.tip').addClass('collapsed');
		    $('.left').addClass('transparent');">
	<img src="../../../_static/minus.png"
         alt="Collapse to compact view" style="padding: 1ex;"/>
	<span class="hiddenlink">Collapse document to compact view</span>
    </a></li>
    <li class="right edit_on_github"><a href="https://github.com/scipy-lectures/scipy-lecture-notes/edit/master/packages/scikit-learn/auto_examples/plot_eigenfaces.rst">Edit
    <span class="tooltip">
	Improve this page:<br/>Edit it on Github.
    </span>
    </a>
    </li>

      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2012,2013,2015,2016,2017.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.6.3.
    </div>
  </body>
</html>